Site Reliability Troubleshooting with Cloud Monitoring APM [ACE]

Overview
The objective of this lab is to familiarize yourself with the specific capabilities of Cloud Monitoring to monitor GKE cluster infrastructure, Istio, and applications deployed on this infrastructure.

What you'll do
Create a GKE cluster

Deploy a microservices application to it

Define latency and error SLIs and SLOs for it

Configure Cloud Monitoring to monitor your SLIs

Deploy a breaking change to the application and use Cloud Monitoring to troubleshoot and resolve the issues that result

Validate that your resolution addresses the SLO violation

What you'll learn
How to deploy a microservices application on an existing GKE cluster

How to select appropriate SLIs/SLOs for an application

How to implement SLIs using Cloud Monitoring features

How to use Cloud Trace, Profiler, and Debugger to identify software issues

Prerequisites
Google Cloud Platform account and project with billing account

Basic knowledge of Kubernetes

Basic knowledge of Cloud Monitoring

Basic knowledge of troubleshooting process

Infrastructure setup

In this lab you will connect to a Google Kubernetes Engine cluster and validate that it's been created correctly.

Set the zone in gcloud:

gcloud config set compute/zone us-west1-b

Set the project ID:

export PROJECT_ID=$(gcloud info --format='value(config.project)')

Verify that the cluster named shop-cluster has been created:

gcloud container clusters list

student_00_79308e59d450@cloudshell:~ (qwiklabs-gcp-00-75ed315da58a)$ gcloud container clusters list
NAME          LOCATION    MASTER_VERSION    MASTER_IP      MACHINE_TYPE   NODE_VERSION      NUM_NODES  STATUS
shop-cluster  us-west1-b  1.17.13-gke.1400  34.83.221.146  n1-standard-2  1.17.13-gke.1400  4          RUNNING

Your cluster status will say PROVISIONING. Wait a moment and run the command above again. Repeat until the status is RUNNING. This could take several minutes.

While you're waiting, set up your Monitoring workspace to monitor the application on your cluster.

Create a Monitoring workspace

Navigation menu > Monitoring.

Wait for your workspace to be provisioned. When the Monitoring dashboard opens, your workspace is ready.

Once your cluster has RUNNING status, get the cluster credentials:

gcloud container clusters get-credentials shop-cluster --zone us-west1-b

Verify that the nodes have been created:

kubectl get nodes

student_00_79308e59d450@cloudshell:~ (qwiklabs-gcp-00-75ed315da58a)$ kubectl get nodes
NAME                                             STATUS   ROLES    AGE     VERSION
gke-shop-cluster-demo-node-pool1-298a8dd9-5ktv   Ready    <none>   5m13s   v1.17.13-gke.1400
gke-shop-cluster-demo-node-pool1-298a8dd9-v5rm   Ready    <none>   5m13s   v1.17.13-gke.1400
gke-shop-cluster-demo-node-pool1-298a8dd9-z6jq   Ready    <none>   5m10s   v1.17.13-gke.1400
gke-shop-cluster-demo-node-pool1-298a8dd9-znlg   Ready    <none>   5m13s   v1.17.13-gke.1400

Deploy application

In this module, you will deploy a microservices application called Hipster Shop to your cluster to create an actual workload you can monitor.

Run the following to clone the repo:

git clone https://github.com/GoogleCloudPlatform/training-data-analyst

https://github.com/GoogleCloudPlatform/training-data-analyst/tree/master/blogs/microservices-demo-1

Create a soft link to your working directory:

ln -s ~/training-data-analyst/blogs/microservices-demo-1 ~/microservices-demo-1

Download and install skaffold:

curl -Lo skaffold https://storage.googleapis.com/skaffold/releases/latest/skaffold-linux-amd64 && chmod +x skaffold && sudo mv skaffold /usr/local/bin

Install the app using skaffold:

cd microservices-demo-1
skaffold run

Confirm everything is running correctly:

kubectl get pods

student_00_79308e59d450@cloudshell:~/microservices-demo-1 (qwiklabs-gcp-00-75ed315da58a)$ kubectl get pods
NAME                                     READY   STATUS    RESTARTS   AGE
adservice-7945957bb9-r2xqp               1/1     Running   0          2m5s
cartservice-5cc59857d4-z4prk             1/1     Running   0          2m5s
checkoutservice-5db86b69cc-pbp4v         1/1     Running   0          2m5s
currencyservice-79cf6fdfc7-k76zn         1/1     Running   0          2m5s
emailservice-674b44dccb-98ckd            1/1     Running   0          2m5s
frontend-64cdd6b48d-4g2cs                1/1     Running   0          2m4s
loadgenerator-779d8445d6-5k24r           1/1     Running   0          2m4s
paymentservice-7758d48b5f-xl6tj          1/1     Running   0          2m4s
productcatalogservice-5b88678d5f-s62nf   1/1     Running   0          2m4s
recommendationservice-65c957669-7pb7p    1/1     Running   0          2m3s
redis-cart-6d9f9fc75-bdz2d               1/1     Running   0          2m3s
shippingservice-545b96f957-bnzdk         1/1     Running   0          2m3s

Re-run the command until all pods are reporting a Running status before moving to the next step.

Get the external IP of the application:

export EXTERNAL_IP=$(kubectl get service frontend-external | awk 'BEGIN { cnt=0; } { cnt+=1; if (cnt > 1) print $4; }')

Finally, confirm that the app is up and running:

curl -o /dev/null -s -w "%{http_code}\n"  http://$EXTERNAL_IP

student_00_79308e59d450@cloudshell:~/microservices-demo-1 (qwiklabs-gcp-00-75ed315da58a)$ curl -o /dev/null -s -w "%{http_code}\n"  http://$EXTERNAL_IP
200

Note: You may need to run this command a second time if you get a 500 error.

Download the source and put the code in the Cloud Source Repo:

./setup_csr.sh

Now that the application has been deployed, set up monitoring for the application.

Resources

Microservices Demo Application
https://github.com/GoogleCloudPlatform/microservices-demo

NOTE: This lab uses a fork (https://github.com/blipzimmerman/microservices-demo-1) of this application build to aid in the troubleshooting exercises.

Skaffold

https://skaffold.dev/

Develop Sample SLOs and SLIs
Before implementing any monitoring, review the introduction to the chapter on Service Level Objectives from the SRE Book:

https://landing.google.com/sre/books/

It's impossible to manage a service correctly, let alone well, without understanding which behaviors really matter for that service and how to measure and evaluate those behaviors. To this end, we would like to define and deliver a given level of service to our users, whether they use an internal API or a public product.

We use intuition, experience and an understanding of what users want to define service level indicators (SLIs), objectives (SLOs) and agreements (SLAs). These measurements describe basic properties of metrics that matter, what values we want those metrics to have and how we'll react if we can't provide the expected service. Ultimately, choosing appropriate metrics helps to drive the right action if something goes wrong and also gives an SRE team confidence that a service is healthy.

An SLI is a service level indicator: A carefully defined quantitative measure of some aspect of the level of service that is provided.

Most services consider

request latency: how long it takes to return a response to a request as a key SLI. Other common SLIs include the error rate, often expressed as a fraction of all requests received and system throughput, typically measured in requests per second. Another kind of SLI important to SREs is availability or the fraction of the time that a service is usable. It is often defined in terms of the fraction of well-formed requests that succeed.

Durability: the likelihood that data will be retained over a long period of time is equally important for data storage systems. The measurements are often aggregated: i.e., raw data is collected over a measurement window and then turned into a rate, average, or percentile.

Now that you have established a basic understanding, define the SLIs and SLOs for your application. Given that the application itself serves end user ecommerce traffic, it's going to be very important that user experience remains constant and that performance is good. You will monitor SLIs for request latency, error rate, throughput and availability.

Application Architecture

It's impossible to develop SLIs without understanding how the application is built. Details are in the original repository, but for this lab, it suffices to understand that:

Users access the application through the Frontend.

Purchases are handled by CheckoutService.

CheckoutService depends on CurrencyService to handle conversions.

Other services such as RecommendationService, ProductCatalogService and Adservice are used to provide the frontend with content needed to render the page.

Configure Latency SLI

Now that you have SLOs and SLIs defined, you can implement cloud monitoring. The metrics you are interested in are already being collected. You will create alerting policies for each of your SLOs.

https://googlecoursera.qwiklabs.com/focuses/12377440?parent=lti_session
https://www.youtube.com/watch?v=_couvE-wm1U